import torch.nn as nn
import torch.nn.functional as F
import torch
import torch.utils.data as Data
import torchvision
import matplotlib.pyplot as plt
import torch.cuda.nccl as nccl
import numpy
import scipy.io as sio
from torchvision.transforms import ToTensor



test = sio.loadmat('database200.mat')

test_data = test['test_data']
test_data = numpy.array(test_data, dtype=numpy.float32)
test_data = torch.from_numpy(numpy.array(test_data))
test_data = test_data.permute(0,3,1,2)
print(test_data.shape)

test_target = test['test_target']
test_target = numpy.array(test_target, dtype=numpy.float32)
test_target = torch.from_numpy(numpy.array(test_target))
print(test_target.shape)

train_data = test['train_data']
train_data = numpy.array(train_data, dtype=numpy.float32)
train_data = torch.from_numpy(numpy.array(train_data))
train_data.requires_grad = True
train_data = train_data.permute(0,3,1,2)
print(train_data.shape)

train_target = test['train_target']
train_target = numpy.array(train_target, dtype=numpy.float32)
train_target = torch.from_numpy(numpy.array(train_target))
print(train_target.shape)

# torch.manual_seed(1)    # reproducible

# Hyper Parameters
EPOCH = 4             # train the training data n times, to save time, we just train 1 epoch
BATCH_SIZE = 8
BATCH_SIZE2 = 1024
LR = 1e-3              # learning rate
TRAIN_SIZE = 1800        # 3437
TEST_SIZE = 40976
MM = 0.95              # momentum

# Data Loader for easy mini-batch return in training
train_loader = Data.DataLoader(dataset = train_data, batch_size = BATCH_SIZE, shuffle = False, num_workers = 2 )
test_loader  = Data.DataLoader(dataset =  test_data, batch_size = BATCH_SIZE2, shuffle = False, num_workers = 2 )

class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Sequential(         # input shape (1, 28, 28)
            nn.Conv2d(
                in_channels = 103,            # input height
                out_channels = 32,          # n_filters
                kernel_size=5,              # filter size
                stride=1,                   # filter movement/step
                padding=3,                  # if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1
            ),         
            nn.Dropout(p=0.7), 
            nn.BatchNorm2d(32),
            nn.ReLU(),                      # activation
            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (16, 14, 14)
        )
        #self.conv2 = nn.Sequential(         # 
            #nn.Conv2d(103, 103, 5, 1, 3),    # 
            #nn.BatchNorm2d(103),
            #nn.Dropout(p=0.08),             
            #nn.ReLU(),                      # activation
            #nn.MaxPool2d(2),                # 
        #
        #self.conv3 = nn.Sequential(         # 
            #nn.Conv2d(57, 32, 5, 1, 3),    # 
            #nn.BatchNorm2d(32),
            #nn.Dropout(p=0.08),             
            #nn.ReLU(),                      # activation
            #nn.MaxPool2d(2),                # 
        #)
        #self.fc = nn.Linear(108, 64)
        self.out = nn.Linear(288, 10)   # fully connected layer, output 9 classes

    def forward(self, x):
        x = self.conv1(x)
        #x = self.conv2(x)
        #x = self.conv3(x)
        #print(x.size())
        #x = x.view(x.size(0), -1)  
        x = x.view(x.size(0), -1) 
        #print(x.size())
        output = self.out(x)
        return output, x    # return x for visualization


cnn = CNN()
print(cnn)  # net architecture


device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)

if torch.cuda.device_count() > 1:
  print("Let's use", torch.cuda.device_count(), "GPUs!")
  cnn = nn.DataParallel(cnn)

cnn = torch.nn.DataParallel(cnn, device_ids=[0]).cuda()

cnn.to(device)

import torch.optim as optim

loss_func = nn.CrossEntropyLoss()                       
#optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)
optimizer = optim.SGD(cnn.parameters(), lr=LR, momentum=MM)

train_target = torch.t(train_target).type(torch.LongTensor).cuda()
test_target = torch.t(test_target).type(torch.LongTensor).cuda()

# training and testing
for epoch in range(EPOCH):
    loss = None
    for step, data in enumerate(train_loader,0):
        
        train_data, train_target = train_data.to(device), train_target.to(device)
        
        optimizer.zero_grad()           # clear gradients for this training step            
        output = cnn(train_data)[0]        # cnn output
        loss = loss_func(output, train_target[0])   # cross entropy loss
        loss.backward()                 # backpropagation, compute gradients
        optimizer.step()                # apply gradients

        if step % 50 == 0:
            test_output, last_layer = cnn(train_data)
            pred_y = torch.max(test_output, 1)[1]
            accuracy = torch.sum(pred_y == train_target[0]).type(torch.FloatTensor) / float(train_target.size(1))
            print('Epoch: ', epoch, '| train loss: ' % loss.data.cpu().numpy(), '| training accuracy: %.3f' % accuracy)
                             
plt.ioff()

#correct = 0
#total = 0
#with torch.no_grad():
#    for data in test_loader:
#        outputs = cnn(test_data)[0]
#        _, predicted = torch.max(outputs, 1)       
        
#correct = torch.eq(predicted, test_target[0])            
#correct = torch.sum(correct)
#correct.dtype
#print(correct.item())
#percent = (correct.item()/TEST_SIZE)
#print('Procent clasificare corecta: %.2f' % percent)


label1=torch.zeros(1,9)
label2=torch.zeros(1,9)
label3=0
label4=0
label5=0
label6=0
correct = 0

with torch.no_grad():
    outputs = cnn(test_data)[0]
    _, predicted = torch.max(outputs, 1)
    c = (predicted == test_target[0]).squeeze()

    predicted = predicted.to(device)
    
    for j in range (40976):
        for i in range (9):
            if (test_target[0,j] == i+1):
                label1[0,i] += 1
            
    for j in range (40976):
        for i in range (9):
            if (predicted[j] == i+1):
                if (c[j] == 1):
                    label2[0,i] += 1 
        if (predicted[j] == 0):
            #print('error: ',predicted[j],'j: ',j)
            label3 += 1
        if (predicted[j] == 8):
            #print('error: ',predicted[j],'j: ',j)
            label4 += 1         
        if (predicted[j] == 9):
            #print('error: ',predicted[j],'j: ',j)
            label5 += 1    
        if (predicted[j] == 10):
            #print('error: ',predicted[j],'j: ',j)
            label6 += 1             
            
    

    #print('clase originale: ',label1)
    #print('clase corecte: ',label2)
    percent = (torch.sum(c).item()/TEST_SIZE)
    print('Procent clasificare corecta: %.2f' % percent)
    print('Rezultate pe clase: ',label2/label1)
    print('Rezultate zero - 0: ',label3)
    print('Rezultate opt - 8: ',label4)
    print('Rezultate noua - 9: ',label5)
    print('Rezultate zece - 10: ',label6) 

torch.cuda.empty_cache()




